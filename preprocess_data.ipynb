{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch, find_peaks\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify path to folder containing training data\n",
    "# directory = 'path/Individuals'\n",
    "directory = '../Data/Participants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothen(df, window_size_ms = 100):\n",
    "    \"\"\"\n",
    "    Applies a sliding window to each column in the given DataFrame.\n",
    "    \"\"\"\n",
    "    # 100 ms equates to sliding window of 5 samples\n",
    "    sampling_interval_ms = 20\n",
    "    window_size_samples = int(window_size_ms / sampling_interval_ms)\n",
    "    return df.rolling(window=window_size_samples, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_borg_df(folder_path, timestamps):\n",
    "    \"\"\"\n",
    "    Given the 'folder_path' to the participant's data, interpolate the borg results linearly according to the timestamps.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(folder_path + '/borg.csv', index_col=0, parse_dates=True)\n",
    "    min_time = df.index.min()\n",
    "    df.index = ((df.index - min_time).total_seconds() * 1000).rename('Timestamp (ms)')\n",
    "    extra_indices = [i for i in list(df.index) if i not in list(timestamps)]\n",
    "    df_reindexed = df.reindex(sorted(list(timestamps) + extra_indices))\n",
    "    df_interpolated = df_reindexed.interpolate(method='linear')\n",
    "    df_interpolated.drop(extra_indices, inplace=True)\n",
    "    return df_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    features = []\n",
    "    features.append(np.mean(data))                           # mean\n",
    "    features.append(np.std(data))                            # standard deviation\n",
    "    features.append(skew(data))                              # skewness\n",
    "    features.append(kurtosis(data))                          # kurtosis\n",
    "    features.append(np.max(data) - np.min(data))             # range\n",
    "    features.append(np.max(data))                            # maximum\n",
    "    features.append(np.min(data))                            # minimum\n",
    "    features.append(np.sqrt(np.mean(data**2)))               # root mean square\n",
    "    features.append(np.corrcoef(data[:-1], data[1:])[0, 1])  # lag 1 autocorrelation\n",
    "\n",
    "    # power spectral density\n",
    "    nperseg = min(256, len(data))\n",
    "    f, Pxx = welch(data, nperseg=nperseg)\n",
    "    features.append(np.sum(Pxx))                             # total power\n",
    "\n",
    "    # fast fourier transform\n",
    "    fft_values = np.abs(fft(data))\n",
    "    fft_freqs = np.fft.fftfreq(len(fft_values))\n",
    "    peaks, _ = find_peaks(fft_values)                        # dominant frequency\n",
    "    features.append(fft_freqs[peaks[0]] if peaks.size > 0 else 0)      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_matrix(data_segment):\n",
    "    feature_matrix = []\n",
    "    for col_index in range(data_segment.shape[1]):\n",
    "        feature_matrix.append(extract_features(data_segment[:, col_index]))\n",
    "    return np.array(feature_matrix).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify path to folder where you want to save features data\n",
    "target_directory = '../Data/Features Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run this to save the features data into the specified target folder\n",
    "individuals_folders = [folder for folder in sorted(os.listdir(directory)) if 'individual' in folder]\n",
    "for individual_folder in individuals_folders:\n",
    "    experiment_folders = [folder for folder in sorted(os.listdir(f'{directory}/{individual_folder}')) if 'experiment' in folder]\n",
    "    for i in range(len(experiment_folders)):\n",
    "        experiment_folder = experiment_folders[i]\n",
    "        folder_path = f'{directory}/{individual_folder}/{experiment_folder}'\n",
    "        new_folder = f'{target_directory}/{individual_folder}/{experiment_folder}'\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder, exist_ok=True)\n",
    "            imu_df = pd.read_csv(f'{folder_path}/imu_data.csv', index_col=0)\n",
    "            timestamps = list(imu_df.index)\n",
    "            borg_df = get_borg_df(folder_path, timestamps)\n",
    "            repetitions_df = pd.read_csv(f'{folder_path}/repetitions.csv')\n",
    "            experiment_X, experiment_y = [], []\n",
    "            for idx, (start, end) in repetitions_df.iterrows():\n",
    "                start_ms = timestamps[start]\n",
    "                end_ms = timestamps[end]\n",
    "                data_segment = imu_df.loc[start_ms : end_ms].values\n",
    "                borg = borg_df.loc[start_ms : end_ms].fatigue.mean()\n",
    "                feature_matrix = extract_feature_matrix(data_segment)\n",
    "                if idx == 0:\n",
    "                    normalization_matrix = np.where(feature_matrix == 0, 1e-8, feature_matrix)\n",
    "                feature_matrix = feature_matrix / normalization_matrix\n",
    "                experiment_X.append(feature_matrix)\n",
    "                experiment_y.append(borg)\n",
    "            np.save(f'{new_folder}/X.npy', np.array(experiment_X), allow_pickle=True)\n",
    "            np.save(f'{new_folder}/y.npy', np.array(experiment_y), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
